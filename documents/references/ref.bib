@inproceedings{dai_automatic_2016,
	title = {Automatic modulation classification using stacked sparse auto-encoders},
	booktitle = {2016 {IEEE} 13th {International} {Conference} on {Signal} {Processing} ({ICSP})},
	author = {Dai, Ao and Zhang, Haijian and Sun, Hong},
	month = nov,
	year = {2016},
	pages = {248--252}
}

@article{huang_data_2020,
	title = {Data {Augmentation} for {Deep} {Learning}-{Based} {Radio} {Modulation} {Classification}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2960775},
	journal = {IEEE Access},
	author = {Huang, Liang and Pan, Weijian and Zhang, You and Qian, Liping and Gao, Nan and Wu, Yuan},
	year = {2020},
	pages = {1498--1506}
}

@inproceedings{qian_modulation_2010,
	title = {Modulation classification based on cyclic spectral features and neural network},
	volume = {8},
	doi = {10.1109/CISP.2010.5647557},
	booktitle = {2010 3rd {International} {Congress} on {Image} and {Signal} {Processing}},
	author = {Qian, Lanjun and Zhu, Canyan},
	month = oct,
	year = {2010}
}

@inproceedings{mendis_deep_2017,
	title = {Deep belief network for automated modulation classification in cognitive radio},
	doi = {10.1109/CCAAW.2017.8001609},
	booktitle = {2017 {Cognitive} {Communications} for {Aerospace} {Applications} {Workshop} ({CCAA})},
	author = {Mendis, Gihan J. and Wei, Jin and Madanayake, Arjuna},
	month = jun,
	year = {2017},
	pages = {1--5}
}

@article{wang_data-driven_2019,
	title = {Data-{Driven} {Deep} {Learning} for {Automatic} {Modulation} {Recognition} in {Cognitive} {Radios}},
	volume = {68},
	issn = {1939-9359},
	doi = {10.1109/TVT.2019.2900460},
	abstract = {Automatic modulation recognition (AMR) is an essential and challenging topic in the development of the cognitive radio (CR), and it is a cornerstone of CR adaptive modulation and demodulation capabilities to sense and learn environments and make corresponding adjustments. AMR is essentially a classification problem, and deep learning achieves outstanding performances in various classification tasks. So, this paper proposes a deep learning-based method, combined with two convolutional neural networks (CNNs) trained on different datasets, to achieve higher accuracy AMR. A CNN is trained on samples composed of in-phase and quadrature component signals, otherwise known as in-phase and quadrature samples, to distinguish modulation modes, that are relatively easy to identify. We adopt dropout instead of pooling operation to achieve higher recognition accuracy. A CNN based on constellation diagrams is also designed to recognize modulation modes that are difficult to distinguish in the former CNN, such as 16 quadratic-amplitude modulation (QAM) and 64 QAM, demonstrating the ability to classify QAM signals even in scenarios with a low signal-to-noise ratio.},
	number = {4},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Wang, Yu and Liu, Miao and Yang, Jie and Gui, Guan},
	month = apr,
	year = {2019},
	keywords = {adaptive modulation, cognitive radio, convolutional neural nets, learning (artificial intelligence), quadrature amplitude modulation, signal classification, telecommunication computing, data-driven deep learning, automatic modulation recognition, cognitive radio, classification tasks, deep learning-based method, convolutional neural networks, higher accuracy AMR, CNN, quadrature samples, modulation modes, higher recognition accuracy, quadratic-amplitude modulation, classification problem, CR adaptive demodulation capability, CR adaptive modulation capability, in-phase component signal, quadrature component signal, constellation diagrams, low signal-to-noise ratio, Constellation diagram, Feature extraction, Task analysis, Training, Deep learning, Signal to noise ratio, Automatic modulation recognition (AMR), cognitive radio (CR), deep learning, convolutional neural network (CNN), in-phase and quadrature (IQ) samples, constellation diagrams},
	pages = {4074--4077}
}

@inproceedings{conn_radio_2019,
	title = {Radio {Frequency} {Classification} and {Anomaly} {Detection} using {Convolutional} {Neural} {Networks}},
	doi = {10.1109/RADAR.2019.8835662},
	abstract = {Radio frequency (RF) spectrum is a limited and critical resource for radar systems. As RF devices become smaller, cheaper and increasingly deployed, they present significant challenges with spectrum sharing and radar interference mitigation. This demands the need for reliable RF sensing and classification techniques for cognitive radars that can dynamically adapt to avoid interference. Our research investigates convolutional neural networks (CNN) trained on waveform images to classify RF spectrum modulations, and two techniques that uses the activations of the last hidden layer of the CNNs to detect anomalies. The CNNs used were AlexNet, GoogleNet, Inception V3, and ResNet50. Our first approach shows that CNNs and Principle Component Analysis (PCA) are highly accurate for classification and anomaly detection. Our second approach shows that appending N-nodes with randomly assigned weights and biases to the last hidden layer may give reasonable performance provided that the weights and biases are carefully selected.},
	booktitle = {2019 {IEEE} {Radar} {Conference} ({RadarConf})},
	author = {Conn, Marvin A. and Josyula, Darsana},
	month = apr,
	year = {2019},
	note = {ISSN: 2375-5318},
	keywords = {convolution, convolutional neural nets, interference suppression, learning (artificial intelligence), principal component analysis, radar interference, radar signal processing, signal classification, telecommunication computing, CNNs, anomaly detection, hidden layer, radio frequency classification, convolutional neural networks, radio frequency spectrum, radar systems, RF devices, spectrum sharing, radar interference mitigation, reliable RF sensing, cognitive radars, waveform images, RF spectrum modulations, principle component analysis, Radar, Anomaly detection, Radio frequency, Detectors, Interference, Principal component analysis, cognitive radar, spectrum sensing, machine learning, neural networks, classifier, anomaly detector},
	pages = {1--6}
}

@inproceedings{dileep_dense_2020,
	title = {Dense {Layer} {Dropout} {Based} {CNN} {Architecture} for {Automatic} {Modulation} {Classification}},
	doi = {10.1109/NCC48643.2020.9055989},
	abstract = {Automatic modulation classification (AMC) is an important part of signal identification for cognitive radio as well as military communication. The problem has been approached traditionally using either likelihood-based or feature-based methods. Since the problem is a classification task, a deep learning (DL) based approach can be an attractive solution. A number of convolutional neural network (CNN) based DL algorithms were introduced for AMC recently. The complex baseband signals that are represented as In-phase and Quadrature (IQ) samples are applied to train the CNN. We propose a new CNN architecture that significantly improves the classification accuracy over existing results in the literature while keeping the number of trainable parameters low. In this architecture, dropouts are applied only in the dense layers.},
	booktitle = {2020 {National} {Conference} on {Communications} ({NCC})},
	author = {Dileep, P and Das, Dibyaiyoti and Bora, Prabin Kumar},
	month = feb,
	year = {2020},
	keywords = {cognitive radio, convolutional neural nets, learning (artificial intelligence), military communication, modulation, neural net architecture, pattern classification, signal classification, IQ samples, in-phase and quadrature samples, CNN-based DL algorithm, dense layer dropout, CNN architecture, classification accuracy, complex baseband signals, convolutional neural network, deep learning based approach, classification task, military communication, automatic modulation classification, AMC, signal identification, cognitive radio, Convolution, Training, Computer architecture, Feature extraction, Quadrature amplitude modulation, Signal to noise ratio, Deep learning, Convolutional neural networks, Automatic modulation classification, IQ samples, Cognitive radio},
	pages = {1--5}
}

@article{liu_deep_2018,
	title = {Deep {Neural} {Network} {Architectures} for {Modulation} {Classification}},
	url = {http://arxiv.org/abs/1712.00443},
	abstract = {In this work, we investigate the value of employing deep learning for the task of wireless signal modulation recognition. Recently in [1], a framework has been introduced by generating a dataset using GNU radio that mimics the imperfections in a real wireless channel, and uses 10 different modulation types. Further, a convolutional neural network (CNN) architecture was developed and shown to deliver performance that exceeds that of expert-based approaches. Here, we follow the framework of [1] and find deep neural network architectures that deliver higher accuracy than the state of the art. We tested the architecture of [1] and found it to achieve an accuracy of approximately 75\% of correctly recognizing the modulation type. We first tune the CNN architecture of [1] and find a design with four convolutional layers and two dense layers that gives an accuracy of approximately 83.8\% at high SNR. We then develop architectures based on the recently introduced ideas of Residual Networks (ResNet [2]) and Densely Connected Networks (DenseNet [3]) to achieve high SNR accuracies of approximately 83.5\% and 86.6\%, respectively. Finally, we introduce a Convolutional Long Short-term Deep Neural Network (CLDNN [4]) to achieve an accuracy of approximately 88.5\% at high SNR.},
	urldate = {2020-07-30},
	journal = {arXiv:1712.00443 [cs, stat]},
	author = {Liu, Xiaoyu and Yang, Diyu and Gamal, Aly El},
	month = jan,
	year = {2018},
	note = {arXiv: 1712.00443},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{wu_convolutional_2019,
	title = {Convolutional neural network and multi-feature fusion for automatic modulation classification},
	volume = {55},
	issn = {0013-5194},
	doi = {10.1049/el.2019.1789},
	abstract = {Automatic modulation classification (AMC) lies at the core of cognitive radio and spectrum sensing. In this Letter, the authors propose a novel convolutional neural network (CNN)-based AMC method with multi-feature fusion. First, the modulation signals are transformed into two image representations of cyclic spectra (CS) and constellation diagram (CD), respectively. Then, a two-branch CNN model is developed, a gradient decent strategy is adopted and a multi-feature fusion technique is exploited to integrate the features learned from CS and CD. The proposed method is computationally efficient, benefited from its simple neural network. Experimental results show that the proposed method can achieve identical or better results with much reduced learned parameters and training time, compared with the state-of-the-art deep learning-based methods.},
	number = {16},
	journal = {Electronics Letters},
	author = {Wu, Hao and Li, Yaxing and Zhou, Liang and Meng, Jin},
	year = {2019},
	keywords = {cognitive radio, convolutional neural nets, feature extraction, image representation, learning (artificial intelligence), modulation, pattern classification, signal classification, signal detection, automatic modulation classification, cognitive radio, spectrum sensing, modulation signals, CS, constellation diagram, CD, two-branch CNN model, gradient decent strategy, multifeature fusion technique, simple neural network, state-of-the-art deep learning-based methods, convolutional neural network-based AMC method},
	pages = {895--897}
}

@inproceedings{roganovic_application_2009,
	title = {Application of artificial neural networks in classification of digital modulations for {Software} {Defined} {Radio}},
	doi = {10.1109/EURCON.2009.5167872},
	abstract = {This paper presents one feature based method for automatic classification and recognition of 7 digital modulations for software defined radio. After reviewing some spectral based features, new statistical based ones are proposed. The classification is conducted with artificial neural networks (ANN). Three architectures are investigated: Multilayer Perceptron (MLP) with one and two hidden layers and Probabilistic Neural Network (PNN). Simulation results for SNR levels of 0, 5, 8, 10 dB are shown. The simulation as well as comparison of these three architectures reveals that MLP with two hidden layers exhibits best classification results with 95\% success rate at 5 dB SNR level, while all of them correctly classify in over 98\% at 10 dB SNR.},
	booktitle = {{IEEE} {EUROCON} 2009},
	author = {Roganovic, Marko M. and Neskovic, Aleksandar M. and Neskovic, Natasa J.},
	month = may,
	year = {2009},
	keywords = {modulation, neural nets, signal classification, software radio, telecommunication computing, artificial neural network, digital modulation recognition, software defined radio, automatic classification, spectral based feature, Application software, Artificial neural networks, Digital modulation, Software radio, OFDM modulation, Feature extraction, Signal processing, AWGN, Computer architecture, Multilayer perceptrons, Automatic Modulation Recognition, Feature selection, Multilayer Perceptron, Probabilistic Neural Network},
	pages = {1700--1706}
}

@inproceedings{kirillov_neural_2018,
	title = {Neural {Algorithm} for {Radio} {Signals} {Modulation} {Classification} of {Satellite} {Communication} {Systems} at {Low} {Signal}-to-{Noise} {Ratio}},
	doi = {10.1109/APEIE.2018.8545769},
	abstract = {Different classification algorithms were considered in the absence of a priori information on the type of modulation, on the basis of which dictionary of feature is proposed. Simulation model was constructed. Experiment was performed to evaluate the parameters of characteristics. Correct probability dependences of modulation classification type on signal-to-noise ratio were obtained.},
	booktitle = {2018 {XIV} {International} {Scientific}-{Technical} {Conference} on {Actual} {Problems} of {Electronics} {Instrument} {Engineering} ({APEIE})},
	author = {Kirillov, Sergey N. and Batishchev, Andrey V.},
	month = oct,
	year = {2018},
	note = {ISSN: 2473-8573},
	keywords = {modulation, neural nets, probability, satellite communication, signal classification, telecommunication computing, a priori information, simulation model, modulation classification type, neural algorithm, satellite communication systems, low signal-to-noise ratio, classification algorithms, radio signal modulation classification, probability dependences, Frequency shift keying, Classification algorithms, Phase shift keying, Quadrature amplitude modulation, Dictionaries, dictionary of feature, classification, type of modulation},
	pages = {45--49}
}

@article{zheng_fusion_2019,
	title = {Fusion {Methods} for {CNN}-{Based} {Automatic} {Modulation} {Classification}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2918136},
	abstract = {An automatic modulation classification has a very broad application in wireless communications. Recently, deep learning has been used to solve this problem and achieved superior performance. In most cases, the input size is fixed in convolutional neural network (CNN)-based modulation classification. However, the duration of the actual radio signal burst is variable. When the signal length is greater than the CNN input length, how to make full use of the complete signal burst to improve the classification accuracy is a problem needs to be considered. In this paper, three fusion methods are proposed to solve this problem, such as voting-based fusion, confidence-based fusion, and feature-based fusion. The simulation experiments are done to analyze the performance of these methods. The results show that the three fusion methods perform better than the non-fusion method. The performance of the two fusion methods based on confidence and feature is very close, which is better than that of the voting-based fusion.},
	journal = {IEEE Access},
	author = {Zheng, Shilian and Qi, Peihan and Chen, Shichuan and Yang, Xiaoniu},
	year = {2019},
	keywords = {convolutional neural nets, learning (artificial intelligence), sensor fusion, signal classification, signal length, CNN input length, voting-based fusion, confidence-based fusion, feature-based fusion, automatic modulation classification, convolutional neural network, radio signal burst, wireless communications, deep learning, Modulation, Convolution, Wireless communication, Deep learning, Training, Convolutional neural networks, Modulation classification, deep learning, fusion, convolutional neural network, residual network, wireless communications, cognitive radio},
	pages = {66496--66504}
}

@inproceedings{guibene_computer_2013,
	title = {Computer vision aided {OFDM}-based standards detection and classification technique for cognitive radio systems},
	doi = {10.1109/ICASSP.2013.6638507},
	abstract = {This paper presents an innovative spectrum sensing scheme for Orthogonal Frequency Division Multiplexing (OFDM) signals based on enhancing the performance of the popular autocorrelation detectors (AD) using non-linear image processing methods. These methods improve the detection accuracy of the AD under particular false-alarm constraints. The proposed scheme is used in the detection of two OFDM systems, Long Term Evolution (LTE) and DVB terrestrial digital TV (DVB-T) under low signal to noise ratio (SNR) channel conditions. Results obtained show significant improvement in correct signals detection/classification up to 18\% and 48\% at a false-alarm of 5\% and low SNR conditions equal to -18dB, using the combined AD and image processing scheme for the detection of LTE and DVB-T signals, respectively.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Guibene, Wael and Khirallah, Chadi and Slock, Dirk and Thompson, John},
	month = may,
	year = {2013},
	note = {ISSN: 2379-190X},
	keywords = {cognitive radio, computer vision, correlation methods, digital video broadcasting, image classification, Long Term Evolution, OFDM modulation, radio spectrum management, signal detection, signal classification, signal detection, low SNR channel condition, low signal to noise ratio channel condition, DVB-T, DVB terrestrial digital TV, LTE, Long Term Evolution, false alarm constraints, nonlinear image processing method, autocorrelation detector, OFDM signal, orthogonal frequency division multiplexing signal, innovative spectrum sensing scheme, cognitive radio system, OFDM-based standards classification technique, OFDM-based standards detection technique, computer vision, Digital video broadcasting, Correlation, Signal to noise ratio, OFDM, Detectors, Standards, Spectrum Sensing, DVB-T, LTE, OFDM},
	pages = {4479--4483}
}

@inproceedings{zhang_supervised_2014,
	title = {Supervised modulation classification based on ambiguity function image and invariant moments},
	doi = {10.1109/ICIEA.2014.6931399},
	abstract = {Automatic modulation classification (AMC) has been a significant research topic in communication systems especially cognitive radio systems. The development of AMC algorithms is still at an immature stage for practical applications. In this paper, a supervised modulation classification scheme is proposed for automatic recognition of different types of communication signals. The supervised classification scheme is based on the distinction of ambiguity function (AF) images of different modulation signals. Two sets of classification feature vectors are exploited from the AF image. One feature vector is a low-dimensional vector by using the principal component analysis (PCA) technique on the AF image. The other feature vector is obtained by computing the invariant moments (IMs) of the AF image due to the different shape information of AF images. Based on the extracted features, the final classification is accomplished through the support vector machine (SVM) classifier. The proposed algorithm is capable to recognize seven different modulation signals: ASK, PSK, QAM, FSK, MSK, LFM and OFDM. Final experimental results demonstrate the efficiency and the robustness of the proposed algorithm in low SNR situations.},
	booktitle = {2014 9th {IEEE} {Conference} on {Industrial} {Electronics} and {Applications}},
	author = {Zhang, Haijian and Bi, Guoan and Razul, Sirajudeen Gulam and See, Chong Meng Samson},
	month = jun,
	year = {2014},
	note = {ISSN: 2158-2297},
	keywords = {cognitive radio, feature extraction, image processing, principal component analysis, support vector machines, ambiguity function image, invariant moments, automatic modulation classification, cognitive radio systems, AMC algorithms, supervised modulation classification scheme, communication signals, AF images, signal modulation, feature vector classification, principal component analysis, PCA technique, IM, support vector machine, SVM classifier, Feature extraction, Signal to noise ratio, Frequency shift keying, OFDM, Vectors, Principal component analysis},
	pages = {1461--1465}
}

@article{gao_fusion_2019,
	title = {Fusion {Image} {Based} {Radar} {Signal} {Feature} {Extraction} and {Modulation} {Recognition}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2892526},
	abstract = {The development of cognitive radio and radar electronic reconnaissance has put forward an important demand for improving the recognition ability of modulated signals in complex electromagnetic environment. In this paper, we propose a valid radar signal modulation recognition technology under low signal-to-noise ratio (SNR). The recognition technology can recognize 12 different modulation signals, including Costas, LFM, NLFM, BPSK, P1-P4, and T1-T4 codes. First, we propose the image fusion algorithm of non-multi-scale decomposition to fuse images of a single signal with different time-frequency (T-F) methods. Specifically, weights are designed by the principal component analysis, which could combine significative details of T-F images. Second, we adopt transfer learning-based convolutional neural networks and self-training-based stacked autoencoder, which extract the effective information on fusion image, furthermore guarantee the recognition performance. Moreover, multi-feature fusion algorithm is used to fuse features, which reduces redundant information on features and enhances computing efficiency. Finally, the classifier is performed by a classical algorithm called support vector machine. Simulation results show that the average recognition success rate is 95.5\% at SNR of -6dB. It is testified that proposed recognition technology possesses good robustness and superiority in RSR with a wide range of SNR.},
	journal = {IEEE Access},
	author = {Gao, Lipeng and Zhang, Xiaoli and Gao, Jingpeng and You, Shixun},
	year = {2019},
	keywords = {convolutional neural nets, feature extraction, image classification, image fusion, learning (artificial intelligence), modulation, principal component analysis, radar computing, radar imaging, support vector machines, time-frequency analysis, recognition ability, modulated signals, complex electromagnetic environment, valid radar signal modulation recognition technology, low signal-to-noise ratio, SNR, image fusion algorithm, nonmultiscale decomposition, single signal, recognition performance, average recognition success rate, proposed recognition technology, cognitive radio, radar electronic reconnaissance, modulation signals, time-frequency methods, fusion image based radar signal feature extraction, fusion image based radar signal modulation recognition, self-training-based stacked autoencoder, transfer learning-based convolutional neural networks, principal component analysis, multifeature fusion algorithm, support vector machine, Costas code, LFM code, NLFM code, BPSK code, P1-P4 code, T1-T4 code, noise figure -6.0 dB, Feature extraction, Modulation, Radar imaging, Image fusion, Image recognition, Signal to noise ratio, Radar signal modulation recognition, time-frequency images, image fusion, multi-feature fusion},
	pages = {13135--13148}
}

@article{liu_classification_2019,
	title = {Classification of {Heterogeneity} on {Multi}-{Spectral} {Transmission} {Image} {Based} on {Modulation}-{Demodulation}-{Frame} {Accumulation} and {Pattern} {Recognition}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2930296},
	abstract = {Multi-spectral transmission image provides a possibility for the detection of early breast cancer. However, in the process of acquiring multi-spectral transmission images, the recognition of heterogeneities has many difficulties due to the image blur caused by the scattering effect of light source in biological tissues and weak transmission signals. This paper proposes a combination method of modulation-demodulation-frame accumulation technique and pattern recognition to achieve heterogeneous classification. First, the acquisition experiment of the phantom multi-spectral images is designed. Then, the signal-to-noise ratio (SNR) of the image is improved by the modulation-demodulation and frame accumulation technique, and the 14-dimensional feature information (firmness, angular second-order distance, contrast, gray-scale correlation, entropy, inverse gap, smoothness, dissimilarity, consistency, center of gravity, area, perimeter, long diameter of irregular image, and short diameter of irregular image) of the heterogeneous region are extracted from the image with high SNR. Finally, the heterogeneous classification accuracy of different models is compared. The results show that: compared with the classification accuracy of the traditional multi-spectral image classification models, random forest (RF) and extreme learning machine (ELM) models have better classification effect when subdividing the four types of heterogeneity based on the data set of this paper. Among them, the RF and ELM models established by the dataset of four-wavelength combination have the best classification effect, and the classification accuracy rate reaches 100\%, second, it is the three-wavelength combined model. The single-wavelength model has the worst classification effect. And the operating efficiency of ELM is significantly higher than RF. In conclusion, the image quality is improved by modulation-demodulation and frame accumulation technique. And compared with the classification accuracy of the traditional multi-spectral image classification models, the RF and ELM models established in this paper have better classification effect, which may promote the application of multi-spectral transmission imaging in early screening of breast tumors.},
	journal = {IEEE Access},
	author = {Liu, Fulong and Li, Gang and Yan, Wenjuan and He, Guoquan and Yang, Shuqiang and Lin, Ling},
	year = {2019},
	keywords = {biological tissues, cancer, feature extraction, image classification, learning (artificial intelligence), medical image processing, pattern classification, phantoms, tumours, pattern recognition, multispectral transmission image, image blur, modulation-demodulation-frame accumulation technique, phantom multispectral images, heterogeneous classification accuracy, traditional multispectral image classification models, classification effect, multispectral transmission imaging, modulation-demodulation-frame accumulation, SNR, ELM, extreme learning machine models, random forest, RF, classification accuracy, Feature extraction, Radio frequency, Breast cancer, Signal to noise ratio, Imaging, Data mining, Multi-spectral transmission image, modulation-demodulation and frame accumulation, heterogeneous classification, pattern recognition},
	pages = {97732--97744}
}

@inproceedings{uppal_high-performance_2019,
	title = {High-{Performance} {Deep} {Learning} {Classification} for {Radio} {Signals}},
	doi = {10.1109/IEEECONF44664.2019.9048897},
	abstract = {The ability to classify different types of signal modulations in radio transmissions is an important task with applications in defense, networking, and communications. This process has traditionally been done manually by human analysts. Recent advances have shown that applying deep learning methods to this task is feasible. But existing recognition networks are complex, with heavy computational requirements, and poor accuracy on some modulation types and in noisy environmentsWe have built a robust radio frequency signal classifier with a hybrid approach that uses images derived from signal constellation and spectrogram data, combined with an efficient convolutional neural network. Compared to the state-of-the-art deep learning classifier, our system obtains better accuracy, with lower computational requirements.},
	booktitle = {2019 53rd {Asilomar} {Conference} on {Signals}, {Systems}, and {Computers}},
	author = {Uppal, Ahsen J. and Hegarty, Michael and Haftel, William and Sallee, Phil A. and Brown Cribbs, H. and Huang, H. Howie},
	month = nov,
	year = {2019},
	note = {ISSN: 2576-2303},
	keywords = {convolutional neural nets, learning (artificial intelligence), modulation, signal classification, high-performance deep learning classification, radio signals, signal modulations, radio transmissions, recognition networks, modulation types, noisy environments, signal constellation, spectrogram data, convolutional neural network, deep learning classifier, radio frequency signal classifier, Deep learning, Spectrogram, Frequency shift keying, Neural networks, Phase shift keying},
	pages = {1026--1029}
}

@inproceedings{he_radio_2019,
	title = {Radio signals modulation mode recognition based on semisupervised deep learning},
	doi = {10.1109/AUTEEE48671.2019.9033373},
	abstract = {With the rapid development of radio communication technology, the application requirement for recognizing modulation mode of radio communication has also increased, therefore it has become a research focus. This paper proposes a method by combining semi-supervised ideas with the CNN network to realize radio modulation recognition. The basic idea is to design a deep learning model based on convolutional neural networks, which will make full use of a large number of unlabeled radio signals in air as well as the labeled radio signals to train convolutional neural networks. Our experimental results illustrate that the performance of our proposed method in recognizing BPSK, QPSK, 8PSK, 4QAM, 16QAM, and 64QAM modulation modes in various environments is better than MLP and CNN.},
	booktitle = {2019 {IEEE} 2nd {International} {Conference} on {Automation}, {Electronics} and {Electrical} {Engineering} ({AUTEEE})},
	author = {He, Xuezhi and Lin, Lin and Xie, Jinbao},
	month = nov,
	year = {2019},
	keywords = {learning (artificial intelligence), quadrature amplitude modulation, quadrature phase shift keying, radiocommunication, telecommunication computing, modulation mode recognition, semisupervised deep learning, radio communication technology, semisupervised ideas, CNN network, radio modulation recognition, deep learning model, convolutional neural networks, unlabeled radio signals, labeled radio signals, 64QAM modulation modes, Feature extraction, Training, Convolutional neural networks, Machine learning, Phase shift keying, Interference, Modulation mode recognition, convolutional neural network, deep learning, semisupervised},
	pages = {330--333}
}

@inproceedings{zhang_deep_2018,
	title = {A {Deep} {Learning} approach for {Modulation} {Recognition}},
	doi = {10.1109/ICDSP.2018.8631811},
	abstract = {Communication signal modulation recognition refers to a process of automatically processing a received signal and determining its modulation type. As an intermediate part of signal detection and demodulation, modulation recognition technology plays an important role in a variety of civilian and military applications such as cognitive radio, electronic reconnaissance, and intelligent demodulator. After several decades of development, modulation recognition technology has made many achievements. However, with the increasing demand for engineering and the increasingly complex wireless communication channel environment, there are still many issues to be solved. This paper presents a method of deep learning for modulation recognition. Deep learning allows for automatically learn features directly from simple wireless signal representations, without the need to design of hand-crafted expert features such as high-order cyclic moments. The neural network used in this paper is the deep belief network. Experimental result shows that using the temporal IQ data representation to recognize modulation formats contributes to the high correct recognition rate at high SNR. When the SNR is 18dB, the average recognition rate still reaches 92.12\%.},
	booktitle = {2018 {IEEE} 23rd {International} {Conference} on {Digital} {Signal} {Processing} ({DSP})},
	author = {ZHANG, Yu and LIU, Tong and ZHANG, Linbo and WANG, Kan},
	month = nov,
	year = {2018},
	note = {ISSN: 2165-3577},
	keywords = {belief networks, data structures, learning (artificial intelligence), modulation, neural nets, signal representation, deep learning approach, civilian applications, military applications, electronic reconnaissance, intelligent demodulator, communication channel environment, deep belief network, wireless signal representations, communication signal modulation recognition technology, signal processing, signal detection, cognitive radio, complex wireless communication channel environment, hand-crafted expert feature design, high-order cyclic moments, temporal IQ data representation, SNR, gain 18.0 dB, Modulation, Feature extraction, Deep learning, Classification algorithms, Wireless communication, Training, Data models, Deep belief network, deep le arning, modulation recognition},
	pages = {1--5}
}
@article{zhou_liu_gravelle_2020, title={Deep Learning for Modulation Recognition: A Survey With a Demonstration}, volume={8}, DOI={10.1109/access.2020.2986330}, journal={IEEE Access}, author={Zhou, Ruolin and Liu, Fugang and Gravelle, Christopher W.}, year={2020}, pages={67366–67376}}

@article{ujan_navidi_landry_2020, title={An Efficient Radio Frequency Interference (RFI) Recognition and Characterization Using End-to-End Transfer Learning}, volume={10}, DOI={10.3390/app10196885}, number={19}, journal={Applied Sciences}, author={Ujan, Sahar and Navidi, Neda and Landry, Rene Jr}, year={2020}, pages={6885}}

@ARTICLE{8789450,
  author={C. {Yang} and Z. {He} and Y. {Peng} and Y. {Wang} and J. {Yang}},
  journal={IEEE Access}, 
  title={Deep Learning Aided Method for Automatic Modulation Recognition}, 
  year={2019},
  volume={7},
  number={},
  pages={109063-109068},}
  
  
  @ARTICLE{8267032,
  author={T. J. {O’Shea} and T. {Roy} and T. C. {Clancy}},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Over-the-Air Deep Learning Based Radio Signal Classification}, 
  year={2018},
  volume={12},
  number={1},
  pages={168-179},
  abstract={We conduct an in depth study on the performance of deep learning based radio signal classification for radio communications signals. We consider a rigorous baseline method using higher order moments and strong boosted gradient tree classification, and compare performance between the two approaches across a range of configurations and channel impairments. We consider the effects of carrier frequency offset, symbol rate, and multipath fading in simulation, and conduct over-the-air measurement of radio classification performance in the lab using software radios, and we compare performance and training strategies for both. Finally, we conclude with a discussion of remaining problems, and design considerations for using such techniques.},
  keywords={fading channels;learning (artificial intelligence);multipath channels;radiocommunication;signal classification;software radio;trees (mathematics);strong boosted gradient tree classification;over-the-air deep learning based radio signal classification;over-the-air measurement;higher order moments;rigorous baseline method;radio communications signals;software radios;Modulation;Feature extraction;Wireless communication;Neural networks;Machine learning;Fading channels;Decision trees;Cognitive radio;deep learning;modulation;neural networks;pattern recognition;sensor systems and applications;wireless communication},
  doi={10.1109/JSTSP.2018.2797022},
  ISSN={1941-0484},
  month={Feb},}
  
  @INPROCEEDINGS{7920754,
  author={N. E. {West} and T. {O'Shea}},
  booktitle={2017 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN)}, 
  title={Deep architectures for modulation recognition}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={We survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition. Results show that radio modulation recognition is not limited by network depth and further work should focus on improving learned synchronization and equalization. Advances in these areas will likely come from novel architectures designed for these tasks or through novel training methods.},
  keywords={learning (artificial intelligence);modulation;neural nets;radiocommunication;signal classification;telecommunication computing;deep architectures;machine learning;deep neural networks;radio modulation recognition;network depth;synchronization learning;equalization learning;Neural networks;Modulation;Training;Computer architecture;Convolution;Dynamic spectrum access;Network architecture},
  doi={10.1109/DySPAN.2017.7920754},
  ISSN={},
  month={March},}
  
@INPROCEEDINGS{8335483,
  author={X. {Liu} and D. {Yang} and A. E. {Gamal}},
  booktitle={2017 51st Asilomar Conference on Signals, Systems, and Computers}, 
  title={Deep neural network architectures for modulation classification}, 
  year={2017},
  volume={},
  number={},
  pages={915-919},}
  
@inproceedings{GAF,
author = {Wang, Zhiguang and Oates, Tim},
title = {Imaging Time-Series to Improve Classification and Imputation},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
abstract = {Inspired by recent successes of deep learning in computer vision, we propose a novel framework for encoding time series as different types of images, namely, Gramian Angular Summation/ Difference Fields (GASF/GADF) and Markov Transition Fields (MTF). This enables the use of techniques from computer vision for time series classification and imputation. We used Tiled Convolutional Neural Networks (tiled CNNs) on 20 standard datasets to learn high-level features from the individual and compound GASF-GADF-MTF images. Our approaches achieve highly competitive results when compared to nine of the current best time series classification approaches. Inspired by the bijection property of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) on the GASF images of four standard and one synthesized compound dataset. The imputation MSE on test data is reduced by 12.18%-48.02% when compared to using the raw data. An analysis of the features and weights learned via tiled CNNs and DAs explains why the approaches work.},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {3939–3945},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {IJCAI'15}
}
@article{markov,
    author = {Campanharo, Andriana S. L. O. AND Sirer, M. Irmak AND Malmgren, R. Dean AND Ramos, Fernando M. AND Amaral, Luís A. Nunes.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Duality between Time Series and Networks},
    year = {2011},
    month = {08},
    volume = {6},
    url = {https://doi.org/10.1371/journal.pone.0023378},
    pages = {1-13},
    abstract = {Studying the interaction between a system's components and the temporal evolution of the system are two common ways to uncover and characterize its internal workings. Recently, several maps from a time series to a network have been proposed with the intent of using network metrics to characterize time series. Although these maps demonstrate that different time series result in networks with distinct topological properties, it remains unclear how these topological properties relate to the original time series. Here, we propose a map from a time series to a network with an approximate inverse operation, making it possible to use network statistics to characterize time series and time series statistics to characterize networks. As a proof of concept, we generate an ensemble of time series ranging from periodic to random and confirm that application of the proposed map retains much of the information encoded in the original time series (or networks) after application of the map (or its inverse). Our results suggest that network analysis can be used to distinguish different dynamic regimes in time series and, perhaps more importantly, time series analysis can provide a powerful set of tools that augment the traditional network analysis toolkit to quantify networks in new and useful ways.},
    number = {8},
    doi = {10.1371/journal.pone.0023378}
}

@InProceedings{rml2016,
author="O'Shea, Timothy J.
and Corgan, Johnathan
and Clancy, T. Charles",
editor="Jayne, Chrisina
and Iliadis, Lazaros",
title="Convolutional Radio Modulation Recognition Networks",
booktitle="Engineering Applications of Neural Networks",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="213--226",
abstract="We study the adaptation of convolutional neural networks to the complex-valued temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert feature based methods which are widely used today and e show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task especially at low signal to noise ratio.",
isbn="978-3-319-44188-7"
}


@ARTICLE{rml2018,
  author={T. J. {O’Shea} and T. {Roy} and T. C. {Clancy}},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Over-the-Air Deep Learning Based Radio Signal Classification}, 
  year={2018},
  volume={12},
  number={1},
  pages={168-179},
  abstract={We conduct an in depth study on the performance of deep learning based radio signal classification for radio communications signals. We consider a rigorous baseline method using higher order moments and strong boosted gradient tree classification, and compare performance between the two approaches across a range of configurations and channel impairments. We consider the effects of carrier frequency offset, symbol rate, and multipath fading in simulation, and conduct over-the-air measurement of radio classification performance in the lab using software radios, and we compare performance and training strategies for both. Finally, we conclude with a discussion of remaining problems, and design considerations for using such techniques.},
  keywords={fading channels;learning (artificial intelligence);multipath channels;radiocommunication;signal classification;software radio;trees (mathematics);strong boosted gradient tree classification;over-the-air deep learning based radio signal classification;over-the-air measurement;higher order moments;rigorous baseline method;radio communications signals;software radios;Modulation;Feature extraction;Wireless communication;Neural networks;Machine learning;Fading channels;Decision trees;Cognitive radio;deep learning;modulation;neural networks;pattern recognition;sensor systems and applications;wireless communication},
  doi={10.1109/JSTSP.2018.2797022},
  ISSN={1941-0484},
  month={Feb},}
  
 @Article{ numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{'{a}}ndez del
                 R{'{\i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@article{pyts,
author    = {Johann Faouzi and Hicham Janati and Ken Keong LEE and Tobias Carryer and Roman Yurchak and AvisP},
title     = {johannfaouzi/pyts: Release of version 0.7.0},
DOI       = {10.5281/zenodo.3568218},
publisher = {Zenodo},
year      = {2019},
month     = {Dec}
}

@INPROCEEDINGS{resnet18,
  author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  abstract={Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  keywords={image classification;learning (artificial intelligence);neural nets;object detection;COCO segmentation;ImageNet localization;ILSVRC & COCO 2015 competitions;deep residual nets;COCO object detection dataset;visual recognition tasks;CIFAR-10;ILSVRC 2015 classification task;ImageNet test set;VGG nets;residual nets;ImageNet dataset;residual function learning;deeper neural network training;image recognition;deep residual learning;Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90},
  ISSN={1063-6919},
  month={June},}